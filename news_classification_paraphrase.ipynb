{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "news_classification_paraphrase.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "mEJcXc61Z7DT"
      },
      "source": [
        "%%capture\n",
        "!pip install sentencepiece\n",
        "!pip install transformers "
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pur9usXTaSi-"
      },
      "source": [
        "from transformers import T5ForConditionalGeneration, T5Tokenizer\n",
        "MODEL_NAME = 'cointegrated/rut5-base-paraphraser'\n",
        "model = T5ForConditionalGeneration.from_pretrained(MODEL_NAME)\n",
        "tokenizer = T5Tokenizer.from_pretrained(MODEL_NAME)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zhUDj7A3aYgu"
      },
      "source": [
        "model.cuda();\n",
        "model.eval();"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BOj7Tc9pa8Tb"
      },
      "source": [
        "def paraphrase(text, beams=5, grams=4, do_sample=False):\n",
        "    x = tokenizer(\n",
        "        text,\n",
        "        return_tensors='pt',\n",
        "        padding=True\n",
        "        ).to(model.device)\n",
        "    max_size = int(x.input_ids.shape[1] * 1.5 + 10)\n",
        "    out = model.generate(\n",
        "        **x,\n",
        "        encoder_no_repeat_ngram_size=grams,\n",
        "        num_beams=beams,\n",
        "        max_length=max_size,\n",
        "        do_sample=do_sample\n",
        "        )\n",
        "    return tokenizer.decode(out[0], skip_special_tokens=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ywJVVQCabNqZ",
        "outputId": "6ef0fee4-29be-4340-8582-fdc6779e7fc6"
      },
      "source": [
        "!wget https://raw.githubusercontent.com/shitkov/news_classification/main/titles.csv"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-08-31 13:41:14--  https://raw.githubusercontent.com/shitkov/news_classification/main/titles.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.109.133, 185.199.108.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 607248 (593K) [text/plain]\n",
            "Saving to: ‘titles.csv.2’\n",
            "\n",
            "\rtitles.csv.2          0%[                    ]       0  --.-KB/s               \rtitles.csv.2        100%[===================>] 593.02K  --.-KB/s    in 0.03s   \n",
            "\n",
            "2021-08-31 13:41:14 (21.1 MB/s) - ‘titles.csv.2’ saved [607248/607248]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0cyq14R3bkwB"
      },
      "source": [
        "import pandas as pd"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vd-Ppvhsbnqw"
      },
      "source": [
        "data = pd.read_csv('/content/titles.csv', index_col=0)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9a32c707bzNk"
      },
      "source": [
        "titles = list(data[data['label'] == 1]['title'])"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H75Bt0UWb3AM"
      },
      "source": [
        "from tqdm import tqdm"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HhS8wCuEciiN",
        "outputId": "65136caf-c5be-4168-f34f-c1fdeaf1ec00"
      },
      "source": [
        "epoch = 4\n",
        "new_titles = []\n",
        "for _ in range(epoch):\n",
        "    for t in tqdm(titles):\n",
        "         new_titles.append(paraphrase(t, do_sample=True))"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 329/329 [02:11<00:00,  2.51it/s]\n",
            "100%|██████████| 329/329 [02:11<00:00,  2.50it/s]\n",
            "100%|██████████| 329/329 [02:11<00:00,  2.51it/s]\n",
            "100%|██████████| 329/329 [02:11<00:00,  2.51it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g1V0W918cyeR"
      },
      "source": [
        "# deduplicate\n",
        "new_titles = list(set(new_titles))"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MRCNr2CedLw0"
      },
      "source": [
        "# save new dataset\n",
        "headlines = pd.DataFrame()\n",
        "headlines['title'] = new_titles\n",
        "headlines['label'] = 1"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jONTG7n_d1vF"
      },
      "source": [
        "# prepare data for concatination\n",
        "data = data.drop(columns = ['sentence'])\n",
        "\n",
        "headlines = pd.concat([headlines, data])\n",
        "\n",
        "headlines.to_csv('/content/headlines.csv' ,index=False)"
      ],
      "execution_count": 27,
      "outputs": []
    }
  ]
}